{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bright-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "jewish-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/etashguha/Downloads/final_mle_dataset.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "operational-license",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1017\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inside-furniture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['product_name', 'product_description', 'prospect_name', 'prospect_industry', 'prospect_title', 'email', 'accepted', 'critique', 'edited', 'email_embedding', 'edited_embedding'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bridal-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted = [obj for obj in data if obj.get('accepted') == 1]\n",
    "rejected = [obj for obj in data if obj.get('accepted') == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "improving-marina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-grocery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rejected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "familiar-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_json_by_keys(json_data, keys):\n",
    "    separated_jsons = {}\n",
    "    for obj in json_data:\n",
    "        key_values = tuple(obj[key] for key in keys)\n",
    "        if key_values not in separated_jsons:\n",
    "            separated_jsons[key_values] = []\n",
    "        separated_jsons[key_values].append(obj)\n",
    "    return separated_jsons\n",
    "sort_key_list = ['prospect_industry']\n",
    "\n",
    "sorted_jsons = separate_json_by_keys(data, sort_key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "local-potato",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/etashguha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/etashguha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_fillers(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    filtered_tokens = [lemmatizer.lemmatize(token.lower(), pos='v') for token in tokens if token.lower() not in stop_words]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "geological-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.upper()\n",
    "    return text\n",
    "\n",
    "critical_words = []\n",
    "changed_words = []\n",
    "removed_words = []\n",
    "for reject in rejected:\n",
    "    critical_words.extend(preprocess_text(remove_fillers(reject[\"critique\"])).split(\" \"))\n",
    "    words_in_original_email = set(preprocess_text(remove_fillers(reject[\"email\"])).split(\" \"))\n",
    "    words_in_new_email = set(preprocess_text(remove_fillers(reject[\"edited\"])).split(\" \"))\n",
    "    changed_words.extend(list(words_in_new_email.difference(words_in_original_email)))\n",
    "    removed_words.extend(list(words_in_original_email.difference(words_in_new_email)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "improved-friendly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('UNDERSTAND', 298),\n",
       " ('BEST', 255),\n",
       " ('REGARD', 207),\n",
       " ('DESIGN', 193),\n",
       " ('S', 188),\n",
       " ('FIND', 170),\n",
       " ('LET', 165),\n",
       " ('KNOW', 164),\n",
       " ('NEED', 162),\n",
       " ('LIKE', 156),\n",
       " ('LOVE', 149),\n",
       " ('DEAR', 149),\n",
       " ('INDUSTRY', 148),\n",
       " ('PROVIDE', 147),\n",
       " ('INTRODUCE', 140),\n",
       " ('DISCUSS', 139),\n",
       " ('WANT', 137),\n",
       " ('EMAIL', 133),\n",
       " ('HELP', 131),\n",
       " ('MAKE', 131),\n",
       " ('IMPORTANCE', 131),\n",
       " ('PLEASE', 127),\n",
       " ('SCHEDULE', 117),\n",
       " ('OFFER', 112),\n",
       " ('BELIEVE', 111),\n",
       " ('BENEFIT', 110),\n",
       " ('IMPORTANT', 109),\n",
       " ('LEARN', 106),\n",
       " ('WOULD', 103),\n",
       " ('ALSO', 99),\n",
       " ('CALL', 99),\n",
       " ('WORK', 97),\n",
       " ('FEATURE', 95),\n",
       " ('QUESTION', 93),\n",
       " ('INTEREST', 92),\n",
       " ('TIME', 92),\n",
       " ('D', 91),\n",
       " ('EXPERIENCE', 90),\n",
       " ('COME', 89),\n",
       " ('SPECIFIC', 89),\n",
       " ('UNIQUE', 84),\n",
       " ('MAY', 83),\n",
       " ('MEET', 83),\n",
       " ('SPECIFICALLY', 81),\n",
       " ('ENSURE', 76),\n",
       " ('REACH', 76),\n",
       " ('WELL', 76),\n",
       " ('LOOK', 74),\n",
       " ('KEEP', 68),\n",
       " ('RE', 68),\n",
       " ('SET', 68),\n",
       " ('US', 68),\n",
       " ('COULD', 67),\n",
       " ('CONSIDERATION', 64),\n",
       " ('HAPPY', 64),\n",
       " ('RANGE', 63),\n",
       " ('ANSWER', 62),\n",
       " ('CLIENTS', 62),\n",
       " ('TAKE', 62),\n",
       " ('ENHANCE', 59),\n",
       " ('DETAIL', 58),\n",
       " ('PRODUCT', 57),\n",
       " ('ALWAYS', 57),\n",
       " ('FELLOW', 57),\n",
       " ('QUALITY', 56),\n",
       " ('CATER', 56),\n",
       " ('INFORMATION', 56),\n",
       " ('FORWARD', 55),\n",
       " ('CONVENIENCE', 54),\n",
       " ('HOPE', 53),\n",
       " ('HIGHQUALITY', 53),\n",
       " ('CONSIDER', 52),\n",
       " ('STAY', 51),\n",
       " ('FREE', 51),\n",
       " ('SHARE', 50),\n",
       " ('CHALLENGE', 49),\n",
       " ('RIGHT', 49),\n",
       " ('TAILOR', 48),\n",
       " ('PROFESSIONAL', 48),\n",
       " ('FIT', 47),\n",
       " ('NAME', 46),\n",
       " ('USE', 46),\n",
       " ('ACROSS', 46),\n",
       " ('PROFESSIONALS', 44),\n",
       " ('SOLUTION', 43),\n",
       " ('RELIABLE', 43),\n",
       " ('HEALTH', 43),\n",
       " ('ASSIST', 43),\n",
       " ('QUICK', 42),\n",
       " ('IMPROVE', 42),\n",
       " ('FEEL', 42),\n",
       " ('GIVE', 41),\n",
       " ('HEAR', 41),\n",
       " ('MIND', 40),\n",
       " ('HEALTHCARE', 39),\n",
       " ('VALUABLE', 39),\n",
       " ('LL', 39),\n",
       " ('HI', 38),\n",
       " ('TECHNOLOGY', 38),\n",
       " ('VALUE', 38)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def find_most_common(lst, n):\n",
    "    counter = Counter(lst)\n",
    "    most_common = counter.most_common(n)\n",
    "    return most_common\n",
    "# find_most_common(critical_words, 100) \n",
    "# rejected[104][\"critique\"]\n",
    "find_most_common(changed_words, 100) \n",
    "# find_most_common(removed_words, 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "toxic-polymer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('entertainment', 19), ('fitness', 13), ('travel', 11), ('game', 10), ('education', 8), ('real', 7), ('estate', 7), ('beauty', 6), ('energy', 6), ('environmental', 4), ('arts', 4), ('transportation', 3), ('interior', 3), ('design', 3), ('architecture', 2), ('clean', 2), ('electrical', 2), ('art', 2), ('ecommerce', 2), ('agriculture', 2), ('law', 2), ('finance', 2), ('environment', 1), ('parent', 1), ('animal', 1), ('welfare', 1), ('', 1), ('dentistry', 1), ('care', 1), ('childcare', 1), ('tourism', 1), ('music', 1), ('landscape', 1), ('enforcement', 1), ('veterinary', 1), ('automotive', 1), ('renewable', 1), ('health', 1)]\n",
      "[('healthcare', 19), ('hospitality', 12), ('sport', 9), ('beverage', 8), ('food', 8), ('business', 5), ('fashion', 5), ('service', 4), ('none', 4), ('technology', 4), ('pediatrics', 3), ('engineer', 2), ('event', 2), ('plan', 2), ('market', 2), ('security', 2), ('construction', 2), ('photography', 1), ('publish', 1), ('manufacture', 1), ('advertise', 1), ('appliances', 1), ('science', 1), ('kitchen', 1), ('bath', 1), ('furniture', 1), ('translation', 1), ('home', 1), ('wellness', 1)]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "accepted_names = []\n",
    "\n",
    "def find_best_and_worst_categories(key):\n",
    "    for accept in accepted:\n",
    "        accepted_names.extend(remove_fillers(preprocess_text(accept[key])).split(\" \"))\n",
    "    rejected_names = []\n",
    "    for reject in rejected:\n",
    "        rejected_names.extend(remove_fillers(preprocess_text(reject[key])).split(\" \"))\n",
    "    good_names = copy.deepcopy(accepted_names)\n",
    "    for bad_name in rejected_names:\n",
    "        if bad_name in good_names:\n",
    "            good_names.remove(bad_name)\n",
    "    bad_names = copy.deepcopy(rejected_names)\n",
    "    for good_name in accepted_names:\n",
    "        if good_name in bad_names:\n",
    "            bad_names.remove(good_name)\n",
    "    print(find_most_common(good_names, 100))\n",
    "    print(find_most_common(bad_names, 100))\n",
    "\n",
    "find_best_and_worst_categories(\"prospect_industry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-tomorrow",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "We will now analyze how to improve the prompts of the GPT algorithm above. We will first examine the weaknesses of GPT.\n",
    "\n",
    "## Weaknesses\n",
    "We see that its weaknesses are across several industries: \"healthcare,\" \"hospitality,\" and \"sport.\" Its best categories are \"entertainment,\" \"fitness,\" and \"travel.\" These categories suggest that in industries where relatability and delicacy are essential traits, our GPT fails. In fact, among many of the critiques, a common thread was that the critics said that GPT was not personable. Looking at a word-by-word analysis, \"empathy\" and \"personalization\" were two of the most common complaints among the critiques.\n",
    "Moreover, one of the most common differences between the original and edited emails was the greetings. GPT often said \"hello\" simply as a greeting, followed by very generic greetings. In the new emails, \"dear,\" \"best,\" and \"regard\" were far more common as salutations. These issues demonstrate that GPT needed to be more personable when writing emails. The new emails included \"please\" and other kinder words more often. Moreover, GPT often mentioned that it is a chatbot, as evidenced by the most commonly removed words. This phrase is very impersonal. \n",
    "\n",
    "Furthermore, GPT often fails when producing information about the industries. Two of the most common words in the critiques were \"generic\" and \"relevant.\" Interestingly, these issues are relevant across many industries. This fact signifies that this is not an issue of GPT not knowing much about the industries but rather not knowing to give more details. Another critical insight is that one of the most common words in the critiques was \"examples.\" GPT often needed to provide relevant examples that would have helped the pitch. \n",
    "\n",
    "Also, one of the most common words in the critiques was \"prospect,\" and one of the most common words in the amended emails was \"need.\" The amended emails often focused on addressing the project's specific needs, and GPT often needed to include information about the prospects. \n",
    "\n",
    "## Prompt Improvement Suggestions\n",
    "I suggest several methods to improve the prompts.\n",
    "\n",
    "### Few-Shot Prompting\n",
    "To address the weakness above, we should give examples of poorly written and good emails according to the critical flaws noted above: personability in greetings and vocabulary, being too generic, giving examples, etc. This method is a common technique for improving the prompts. We should list the weaknesses above alongside examples of emails that fix and don't fix the fault to help GPT lean towards good emails. \n",
    "\n",
    "### Set Rules\n",
    "We need to set some rules. We can include in the prompt explicit rules such as \"say please more often\" and \"do not mention you are a chatbot.\" We can set these rules per the weaknesses above to weed out poor behaviors of GPT. \n",
    "\n",
    "### Generate Knowledge Prompting\n",
    "We can ask GPT to predict how the prospect could use the product. Then, finally, we can tell GPT in a final promptly to include this information in the email. This addition to the prompting could help GPT to focus on more details of the prospect that genuinely benefit the prospect and be more effective at sales. \n",
    "\n",
    "### Simulus Prompting\n",
    "We can ask GPT itself to rank several emails given the prompts. Then, using this reranker, we can generate several potential emails and output the one that GPT identifies that fixes the weaknesses above. This technique has been shown to reflect human annotations more reliably than zero-shot prompting, in general, more empirically. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-great",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-military",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
